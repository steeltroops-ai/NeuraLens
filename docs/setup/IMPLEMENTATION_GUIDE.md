# NeuroLens-X: Technical Architecture

## âš ï¸ **IMPLEMENTATION STATUS REALITY CHECK**

### **Current vs Documented Architecture**

| Component | Documented | Actual Status | Action Required |
|-----------|------------|---------------|-----------------|
| **Frontend Components** | âœ… Complete | âš ï¸ Partial | Connect to working backend APIs |
| **Backend API Endpoints** | âœ… 6 endpoints | âŒ Only 1 exists | Implement 5 missing endpoints |
| **ML Model Pipeline** | âœ… 4 modalities | âŒ Interface only | Implement working ML inference |
| **Database Models** | âœ… Complete | âš ï¸ Uncertain | Verify and complete models |
| **PWA Features** | âœ… Documented | âŒ Not implemented | Implement service worker |
| **Demo Data** | âœ… Planned | âŒ Missing | Generate synthetic datasets |

### **Critical Gap Analysis**
- **Functionality Gap**: System may not work end-to-end for judges
- **Demo Gap**: No test data available for judge evaluation
- **Integration Gap**: Frontend-backend connection uncertain
- **Validation Gap**: No working clinical validation metrics

---

## ðŸ—ï¸ **SYSTEM ARCHITECTURE OVERVIEW**

```mermaid
graph TB
    subgraph "Frontend Layer"
        PWA[Progressive Web App]
        UI[React/Next.js UI]
        SW[Service Worker]
    end
    
    subgraph "API Gateway"
        API[FastAPI Backend]
        AUTH[Authentication]
        RATE[Rate Limiting]
    end
    
    subgraph "ML Pipeline"
        SPEECH[Speech Analysis]
        RETINAL[Retinal Classification]
        RISK[Risk Assessment]
        FUSION[NRI Fusion]
    end
    
    subgraph "Data Layer"
        DB[(PostgreSQL)]
        REDIS[(Redis Cache)]
        FILES[File Storage]
    end
    
    PWA --> API
    API --> SPEECH
    API --> RETINAL
    API --> RISK
    SPEECH --> FUSION
    RETINAL --> FUSION
    RISK --> FUSION
    API --> DB
    API --> REDIS
    API --> FILES
```

---

## ðŸ’» **FRONTEND ARCHITECTURE**

### **Technology Stack**
```typescript
// Core Framework
â”œâ”€â”€ Next.js 14 (App Router)
â”œâ”€â”€ React 18 (Concurrent Features)
â”œâ”€â”€ TypeScript (Strict Mode)
â”œâ”€â”€ Tailwind CSS (Design System)
â””â”€â”€ PWA (Service Worker)

// State Management
â”œâ”€â”€ Zustand (Global State)
â”œâ”€â”€ React Query (Server State)
â”œâ”€â”€ React Hook Form (Form State)
â””â”€â”€ Local Storage (Persistence)

// UI Components
â”œâ”€â”€ Shadcn/ui (Component Library)
â”œâ”€â”€ Framer Motion (Animations)
â”œâ”€â”€ Chart.js (Data Visualization)
â””â”€â”€ React PDF (Report Generation)
```

### **Component Architecture**
```typescript
// Component Hierarchy
src/
â”œâ”€â”€ app/                    # Next.js App Router
â”‚   â”œâ”€â”€ assess/            # Assessment flow pages
â”‚   â”œâ”€â”€ results/           # Results display pages
â”‚   â””â”€â”€ dashboard/         # Analytics dashboard
â”œâ”€â”€ components/            # Reusable components
â”‚   â”œâ”€â”€ ui/               # Base UI components
â”‚   â”œâ”€â”€ forms/            # Form components
â”‚   â”œâ”€â”€ charts/           # Visualization components
â”‚   â””â”€â”€ layout/           # Layout components
â”œâ”€â”€ hooks/                # Custom React hooks
â”‚   â”œâ”€â”€ useAssessment.ts  # Assessment state management
â”‚   â”œâ”€â”€ useML.ts          # ML model interactions
â”‚   â””â”€â”€ useResults.ts     # Results processing
â”œâ”€â”€ lib/                  # Utility libraries
â”‚   â”œâ”€â”€ api.ts           # API client
â”‚   â”œâ”€â”€ utils.ts         # Helper functions
â”‚   â””â”€â”€ validations.ts   # Form validations
â””â”€â”€ types/               # TypeScript definitions
    â”œâ”€â”€ assessment.ts    # Assessment types
    â”œâ”€â”€ results.ts       # Results types
    â””â”€â”€ api.ts          # API response types
```

### **PWA Configuration**
```typescript
// next.config.js
const withPWA = require('next-pwa')({
  dest: 'public',
  register: true,
  skipWaiting: true,
  runtimeCaching: [
    {
      urlPattern: /^https:\/\/api\.neurolens-x\.com\/.*/,
      handler: 'NetworkFirst',
      options: {
        cacheName: 'api-cache',
        networkTimeoutSeconds: 10,
      },
    },
    {
      urlPattern: /\.(?:png|jpg|jpeg|svg)$/,
      handler: 'CacheFirst',
      options: {
        cacheName: 'images',
        expiration: {
          maxEntries: 100,
          maxAgeSeconds: 30 * 24 * 60 * 60, // 30 days
        },
      },
    },
  ],
})
```

---

## ðŸ”§ **BACKEND ARCHITECTURE**

### **Technology Stack**
```python
# Core Framework
â”œâ”€â”€ FastAPI (Async Web Framework)
â”œâ”€â”€ Pydantic (Data Validation)
â”œâ”€â”€ SQLAlchemy (ORM)
â”œâ”€â”€ Alembic (Database Migrations)
â””â”€â”€ Uvicorn (ASGI Server)

# ML/Data Processing
â”œâ”€â”€ scikit-learn (Classical ML)
â”œâ”€â”€ XGBoost (Gradient Boosting)
â”œâ”€â”€ TensorFlow/PyTorch (Deep Learning)
â”œâ”€â”€ Librosa (Audio Processing)
â”œâ”€â”€ OpenCV (Image Processing)
â””â”€â”€ NumPy/Pandas (Data Manipulation)

# Infrastructure
â”œâ”€â”€ PostgreSQL (Primary Database)
â”œâ”€â”€ Redis (Caching & Sessions)
â”œâ”€â”€ Celery (Background Tasks)
â””â”€â”€ Docker (Containerization)
```

### **API Structure**
```python
# FastAPI Application Structure
app/
â”œâ”€â”€ main.py                 # Application entry point
â”œâ”€â”€ core/                   # Core configuration
â”‚   â”œâ”€â”€ config.py          # Settings and environment
â”‚   â”œâ”€â”€ security.py        # Authentication & authorization
â”‚   â””â”€â”€ database.py        # Database connection
â”œâ”€â”€ api/                    # API routes
â”‚   â”œâ”€â”€ v1/                # API version 1
â”‚   â”‚   â”œâ”€â”€ endpoints/     # Route handlers
â”‚   â”‚   â”‚   â”œâ”€â”€ assess.py  # Assessment endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ results.py # Results endpoints
â”‚   â”‚   â”‚   â””â”€â”€ models.py  # ML model endpoints
â”‚   â”‚   â””â”€â”€ api.py         # API router
â”œâ”€â”€ models/                 # Database models
â”‚   â”œâ”€â”€ user.py            # User model
â”‚   â”œâ”€â”€ assessment.py      # Assessment model
â”‚   â””â”€â”€ results.py         # Results model
â”œâ”€â”€ schemas/                # Pydantic schemas
â”‚   â”œâ”€â”€ assessment.py      # Assessment schemas
â”‚   â”œâ”€â”€ results.py         # Results schemas
â”‚   â””â”€â”€ user.py           # User schemas
â”œâ”€â”€ services/               # Business logic
â”‚   â”œâ”€â”€ ml_service.py      # ML model service
â”‚   â”œâ”€â”€ assessment_service.py # Assessment logic
â”‚   â””â”€â”€ report_service.py  # Report generation
â””â”€â”€ ml/                     # ML pipeline
    â”œâ”€â”€ models/            # Trained models
    â”œâ”€â”€ speech/            # Speech analysis
    â”œâ”€â”€ retinal/           # Retinal classification
    â”œâ”€â”€ risk/              # Risk assessment
    â””â”€â”€ fusion/            # NRI fusion
```

### **Database Schema**
```sql
-- Core Tables
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE assessments (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id),
    status VARCHAR(50) DEFAULT 'pending',
    created_at TIMESTAMP DEFAULT NOW(),
    completed_at TIMESTAMP
);

CREATE TABLE assessment_results (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    assessment_id UUID REFERENCES assessments(id),
    speech_score FLOAT,
    retinal_score FLOAT,
    risk_score FLOAT,
    nri_score FLOAT,
    confidence_interval JSONB,
    recommendations TEXT,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE uploaded_files (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    assessment_id UUID REFERENCES assessments(id),
    file_type VARCHAR(50), -- 'audio', 'retinal'
    file_path VARCHAR(500),
    file_size INTEGER,
    uploaded_at TIMESTAMP DEFAULT NOW()
);
```

---

## ðŸ§  **ML PIPELINE ARCHITECTURE**

### **Model Pipeline Overview**
```python
# ML Pipeline Structure
ml_pipeline/
â”œâ”€â”€ preprocessing/          # Data preprocessing
â”‚   â”œâ”€â”€ audio_processor.py # Audio feature extraction
â”‚   â”œâ”€â”€ image_processor.py # Image preprocessing
â”‚   â””â”€â”€ risk_processor.py  # Risk factor processing
â”œâ”€â”€ models/                # ML models
â”‚   â”œâ”€â”€ speech_model.py    # Speech analysis model
â”‚   â”œâ”€â”€ retinal_model.py   # Retinal classification
â”‚   â”œâ”€â”€ risk_model.py      # Risk assessment model
â”‚   â””â”€â”€ fusion_model.py    # NRI fusion model
â”œâ”€â”€ inference/             # Model inference
â”‚   â”œâ”€â”€ speech_inference.py
â”‚   â”œâ”€â”€ retinal_inference.py
â”‚   â”œâ”€â”€ risk_inference.py
â”‚   â””â”€â”€ fusion_inference.py
â”œâ”€â”€ validation/            # Model validation
â”‚   â”œâ”€â”€ metrics.py         # Performance metrics
â”‚   â”œâ”€â”€ calibration.py     # Model calibration
â”‚   â””â”€â”€ fairness.py        # Bias detection
â””â”€â”€ utils/                 # Utility functions
    â”œâ”€â”€ feature_extraction.py
    â”œâ”€â”€ uncertainty.py     # Uncertainty quantification
    â””â”€â”€ visualization.py   # Result visualization
```

### **Speech Analysis Pipeline**
```python
# Speech Processing Architecture
class SpeechAnalyzer:
    def __init__(self):
        self.feature_extractor = AudioFeatureExtractor()
        self.model = XGBoostClassifier()
        self.uncertainty_estimator = UncertaintyQuantifier()
    
    def analyze(self, audio_file: bytes) -> SpeechResult:
        # 1. Audio preprocessing
        audio_data = self.preprocess_audio(audio_file)
        
        # 2. Feature extraction
        features = self.feature_extractor.extract(audio_data)
        
        # 3. Model inference
        prediction = self.model.predict_proba(features)
        
        # 4. Uncertainty quantification
        confidence = self.uncertainty_estimator.estimate(features, prediction)
        
        return SpeechResult(
            score=prediction[1] * 100,
            confidence_interval=confidence,
            features=features.to_dict()
        )
```

### **Retinal Classification Pipeline**
```python
# Retinal Processing Architecture
class RetinalAnalyzer:
    def __init__(self):
        self.preprocessor = ImagePreprocessor()
        self.model = CNNClassifier()
        self.vessel_analyzer = VesselAnalyzer()
    
    def analyze(self, image_file: bytes) -> RetinalResult:
        # 1. Image preprocessing
        image = self.preprocessor.process(image_file)
        
        # 2. CNN classification
        pathology_score = self.model.predict(image)
        
        # 3. Vessel analysis
        vessel_metrics = self.vessel_analyzer.analyze(image)
        
        # 4. Combined scoring
        combined_score = self.combine_scores(pathology_score, vessel_metrics)
        
        return RetinalResult(
            score=combined_score,
            pathology_probability=pathology_score,
            vessel_metrics=vessel_metrics
        )
```

### **NRI Fusion Algorithm**
```python
# Multi-Modal Fusion Architecture
class NRIFusion:
    def __init__(self):
        self.weights = {
            'speech': 0.25,
            'retinal': 0.30,
            'risk': 0.35,
            'motor': 0.10
        }
        self.uncertainty_propagator = UncertaintyPropagator()
    
    def calculate_nri(self, 
                     speech_result: SpeechResult,
                     retinal_result: RetinalResult,
                     risk_result: RiskResult) -> NRIResult:
        
        # 1. Weighted combination
        nri_score = (
            self.weights['speech'] * speech_result.score +
            self.weights['retinal'] * retinal_result.score +
            self.weights['risk'] * risk_result.score
        )
        
        # 2. Uncertainty propagation
        confidence_interval = self.uncertainty_propagator.propagate([
            speech_result.confidence_interval,
            retinal_result.confidence_interval,
            risk_result.confidence_interval
        ])
        
        # 3. Risk stratification
        risk_category = self.stratify_risk(nri_score)
        
        return NRIResult(
            nri_score=nri_score,
            risk_category=risk_category,
            confidence_interval=confidence_interval,
            recommendations=self.generate_recommendations(nri_score, risk_category)
        )
```

---

## ðŸ”’ **SECURITY ARCHITECTURE**

### **Authentication & Authorization**
```python
# Security Configuration
SECURITY_CONFIG = {
    "JWT_SECRET_KEY": os.getenv("JWT_SECRET_KEY"),
    "JWT_ALGORITHM": "HS256",
    "ACCESS_TOKEN_EXPIRE_MINUTES": 30,
    "REFRESH_TOKEN_EXPIRE_DAYS": 7,
    "PASSWORD_MIN_LENGTH": 8,
    "RATE_LIMIT_PER_MINUTE": 60
}

# CORS Configuration
CORS_CONFIG = {
    "allow_origins": ["https://neurolens-x.com"],
    "allow_credentials": True,
    "allow_methods": ["GET", "POST", "PUT", "DELETE"],
    "allow_headers": ["*"]
}
```

### **Data Privacy & Compliance**
```python
# Privacy Configuration
PRIVACY_CONFIG = {
    "data_retention_days": 90,
    "anonymization_enabled": True,
    "encryption_at_rest": True,
    "audit_logging": True,
    "gdpr_compliance": True
}

# File Upload Security
UPLOAD_CONFIG = {
    "max_file_size": 50 * 1024 * 1024,  # 50MB
    "allowed_audio_types": [".wav", ".mp3", ".m4a"],
    "allowed_image_types": [".jpg", ".jpeg", ".png"],
    "virus_scanning": True,
    "content_validation": True
}
```

---

## ðŸ“Š **MONITORING & OBSERVABILITY**

### **Performance Monitoring**
```python
# Monitoring Configuration
MONITORING_CONFIG = {
    "metrics_collection": True,
    "performance_tracking": True,
    "error_tracking": True,
    "user_analytics": True,
    "ml_model_monitoring": True
}

# Key Performance Indicators
KPI_METRICS = {
    "response_time_p95": 500,  # milliseconds
    "error_rate_threshold": 0.01,  # 1%
    "availability_target": 0.999,  # 99.9%
    "ml_accuracy_threshold": 0.80  # 80%
}
```

### **Logging Strategy**
```python
# Logging Configuration
LOGGING_CONFIG = {
    "level": "INFO",
    "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    "handlers": ["console", "file", "elasticsearch"],
    "sensitive_data_masking": True,
    "structured_logging": True
}
```

---

## ðŸš€ **DEPLOYMENT ARCHITECTURE**

### **Containerization**
```dockerfile
# Multi-stage Docker build
FROM node:18-alpine AS frontend-builder
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY . .
RUN npm run build

FROM python:3.11-slim AS backend
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
EXPOSE 8000
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### **Infrastructure as Code**
```yaml
# Docker Compose for local development
version: '3.8'
services:
  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8000
  
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:pass@db:5432/neurolens
      - REDIS_URL=redis://redis:6379
    depends_on:
      - db
      - redis
  
  db:
    image: postgres:15
    environment:
      - POSTGRES_DB=neurolens
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
    volumes:
      - postgres_data:/var/lib/postgresql/data
  
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

volumes:
  postgres_data:
```

---

*This architecture ensures scalable, secure, and maintainable development while supporting the 50-hour hackathon timeline.*
